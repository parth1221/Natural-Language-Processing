{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Accessing a LEXICON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mere Wordlist\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMU Wordlist\n",
    "entries = nltk.corpus.cmudict.entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "(\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "(\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D', 'Z'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D', 'Z'])\n",
      "('belgrave', ['B', 'EH1', 'L', 'G', 'R', 'EY2', 'V'])\n",
      "('beli', ['B', 'EH1', 'L', 'IY0'])\n",
      "('belich', ['B', 'EH1', 'L', 'IH0', 'K'])\n",
      "('belie', ['B', 'IH0', 'L', 'AY1'])\n",
      "('belied', ['B', 'IH0', 'L', 'AY1', 'D'])\n",
      "('belief', ['B', 'IH0', 'L', 'IY1', 'F'])\n",
      "('beliefs', ['B', 'IH0', 'L', 'IY1', 'F', 'S'])\n",
      "('belier', ['B', 'EH1', 'L', 'Y', 'ER0'])\n",
      "('belies', ['B', 'IH0', 'L', 'AY1', 'Z'])\n",
      "('believability', ['B', 'AH0', 'L', 'IY2', 'V', 'AH0', 'B', 'IH1', 'L', 'IH0', 'T', 'IY0'])\n",
      "('believable', ['B', 'AH0', 'L', 'IY1', 'V', 'AH0', 'B', 'AH0', 'L'])\n",
      "('believe', ['B', 'IH0', 'L', 'IY1', 'V'])\n",
      "('believed', ['B', 'IH0', 'L', 'IY1', 'V', 'D'])\n",
      "('believer', ['B', 'AH0', 'L', 'IY1', 'V', 'ER0'])\n",
      "('believers', ['B', 'AH0', 'L', 'IY1', 'V', 'ER0', 'Z'])\n",
      "('believes', ['B', 'IH0', 'L', 'IY1', 'V', 'Z'])\n",
      "('believing', ['B', 'IH0', 'L', 'IY1', 'V', 'IH0', 'NG'])\n",
      "('beligerence', ['B', 'AH0', 'L', 'IH1', 'JH', 'ER0', 'AH0', 'N', 'S'])\n",
      "('beligerent', ['B', 'AH0', 'L', 'IH1', 'JH', 'ER0', 'AH0', 'N', 'T'])\n",
      "('belin', ['B', 'EH1', 'L', 'IH0', 'N'])\n",
      "('belinda', ['B', 'AH0', 'L', 'IH1', 'N', 'D', 'AH0'])\n",
      "('belinsky', ['B', 'IH0', 'L', 'IH1', 'N', 'S', 'K', 'IY0'])\n",
      "('belisle', ['B', 'EH1', 'L', 'AY0', 'AH0', 'L'])\n",
      "('belittle', ['B', 'IH0', 'L', 'IH1', 'T', 'AH0', 'L'])\n",
      "('belittled', ['B', 'IH0', 'L', 'IH1', 'T', 'AH0', 'L', 'D'])\n",
      "('belittles', ['B', 'IH0', 'L', 'IH1', 'T', 'AH0', 'L', 'Z'])\n",
      "('belittling', ['B', 'IH0', 'L', 'IH1', 'T', 'AH0', 'L', 'IH0', 'NG'])\n",
      "('belittling', ['B', 'IH0', 'L', 'IH1', 'T', 'L', 'IH0', 'NG'])\n",
      "('belitz', ['B', 'EH1', 'L', 'IH0', 'T', 'S'])\n",
      "('beliveau', ['B', 'EH1', 'L', 'IH0', 'V', 'OW2'])\n",
      "('belize', ['B', 'EH0', 'L', 'IY1', 'Z'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[10000: 10050]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordnet\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('motorcar') # returns an ID for the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: \"01')]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1d8c73a2f69d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[Synset(\\'car.n.01\\')]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# head words/lemmas in the subset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36msynset\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;31m# split name into lemma, part of speech and synset number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \u001b[0mlemma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynset_index_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m         \u001b[0msynset_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset_index_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m         \u001b[1;31m# get the offset for this synset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: \"01')]\""
     ]
    }
   ],
   "source": [
    "wn.synset('n').lemma_name() # head words/lemmas in the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NLTK Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"\"\"Leonardo Wilhelm DiCaprio (/dɪˈkæprioʊ/, Italian: [diˈkaːprjo]; born November 11, 1974) is an American actor, producer, and environmentalist. He has often played unconventional parts, particularly in biopics and period films. As of 2019, his films have earned US$7.2 billion worldwide, and he has placed eight times in annual rankings of the world's highest-paid actors. His accolades include an Academy Award and three Golden Globe Awards.\n",
    "\n",
    "Born in Los Angeles, DiCaprio began his career by appearing in television commercials in the late 1980s. In the early 1990s, he played recurring roles in various television series, such as the sitcom Parenthood. He had his first major film role in This Boy's Life, and received acclaim for the supporting role of a developmentally disabled boy in What's Eating Gilbert Grape (both 1993), which earned him an Academy Award nomination. He achieved international fame as a star in the epic romance Titanic (1997), which became the highest-grossing film at that point. After a few commercially failed films, DiCaprio starred in two successful features in 2002: the biographical crime drama Catch Me If You Can and the historical drama Gangs of New York, which marked his first of many collaborations with director Martin Scorsese.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leonardo Wilhelm DiCaprio (/dɪˈkæprioʊ/, Italian: [diˈkaːprjo]; born November 11, 1974) is an American actor, producer, and environmentalist.', 'He has often played unconventional parts, particularly in biopics and period films.', \"As of 2019, his films have earned US$7.2 billion worldwide, and he has placed eight times in annual rankings of the world's highest-paid actors.\", 'His accolades include an Academy Award and three Golden Globe Awards.', 'Born in Los Angeles, DiCaprio began his career by appearing in television commercials in the late 1980s.', 'In the early 1990s, he played recurring roles in various television series, such as the sitcom Parenthood.', \"He had his first major film role in This Boy's Life, and received acclaim for the supporting role of a developmentally disabled boy in What's Eating Gilbert Grape (both 1993), which earned him an Academy Award nomination.\", 'He achieved international fame as a star in the epic romance Titanic (1997), which became the highest-grossing film at that point.', 'After a few commercially failed films, DiCaprio starred in two successful features in 2002: the biographical crime drama Catch Me If You Can and the historical drama Gangs of New York, which marked his first of many collaborations with director Martin Scorsese.']\n",
      "[('Leonardo', 'NNP'), ('Wilhelm', 'NNP'), ('DiCaprio', 'NNP'), ('(', '('), ('/dɪˈkæprioʊ/', 'NNP'), (',', ','), ('Italian', 'JJ'), (':', ':'), ('[', 'JJ'), ('diˈkaːprjo', 'NN'), (']', 'NN'), (';', ':'), ('born', 'VBN'), ('November', 'NNP'), ('11', 'CD'), (',', ','), ('1974', 'CD'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('American', 'JJ'), ('actor', 'NN'), (',', ','), ('producer', 'NN'), (',', ','), ('and', 'CC'), ('environmentalist', 'NN'), ('.', '.')]\n",
      "[('He', 'PRP'), ('has', 'VBZ'), ('often', 'RB'), ('played', 'VBN'), ('unconventional', 'JJ'), ('parts', 'NNS'), (',', ','), ('particularly', 'RB'), ('in', 'IN'), ('biopics', 'NNS'), ('and', 'CC'), ('period', 'NN'), ('films', 'NNS'), ('.', '.')]\n",
      "[('As', 'IN'), ('of', 'IN'), ('2019', 'CD'), (',', ','), ('his', 'PRP$'), ('films', 'NNS'), ('have', 'VBP'), ('earned', 'VBN'), ('US', 'NNP'), ('$', '$'), ('7.2', 'CD'), ('billion', 'CD'), ('worldwide', 'NN'), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('has', 'VBZ'), ('placed', 'VBN'), ('eight', 'CD'), ('times', 'NNS'), ('in', 'IN'), ('annual', 'JJ'), ('rankings', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('highest-paid', 'JJ'), ('actors', 'NNS'), ('.', '.')]\n",
      "[('His', 'PRP$'), ('accolades', 'NNS'), ('include', 'VBP'), ('an', 'DT'), ('Academy', 'NNP'), ('Award', 'NNP'), ('and', 'CC'), ('three', 'CD'), ('Golden', 'NNP'), ('Globe', 'NNP'), ('Awards', 'NNP'), ('.', '.')]\n",
      "[('Born', 'NNP'), ('in', 'IN'), ('Los', 'NNP'), ('Angeles', 'NNP'), (',', ','), ('DiCaprio', 'NNP'), ('began', 'VBD'), ('his', 'PRP$'), ('career', 'NN'), ('by', 'IN'), ('appearing', 'VBG'), ('in', 'IN'), ('television', 'NN'), ('commercials', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('late', 'JJ'), ('1980s', 'NNS'), ('.', '.')]\n",
      "[('In', 'IN'), ('the', 'DT'), ('early', 'JJ'), ('1990s', 'CD'), (',', ','), ('he', 'PRP'), ('played', 'VBD'), ('recurring', 'VBG'), ('roles', 'NNS'), ('in', 'IN'), ('various', 'JJ'), ('television', 'NN'), ('series', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('the', 'DT'), ('sitcom', 'NN'), ('Parenthood', 'NNP'), ('.', '.')]\n",
      "[('He', 'PRP'), ('had', 'VBD'), ('his', 'PRP$'), ('first', 'JJ'), ('major', 'JJ'), ('film', 'NN'), ('role', 'NN'), ('in', 'IN'), ('This', 'DT'), ('Boy', 'NNP'), (\"'s\", 'POS'), ('Life', 'NNP'), (',', ','), ('and', 'CC'), ('received', 'VBD'), ('acclaim', 'NN'), ('for', 'IN'), ('the', 'DT'), ('supporting', 'VBG'), ('role', 'NN'), ('of', 'IN'), ('a', 'DT'), ('developmentally', 'RB'), ('disabled', 'JJ'), ('boy', 'NN'), ('in', 'IN'), ('What', 'WP'), (\"'s\", 'VBZ'), ('Eating', 'VBG'), ('Gilbert', 'NNP'), ('Grape', 'NNP'), ('(', '('), ('both', 'DT'), ('1993', 'CD'), (')', ')'), (',', ','), ('which', 'WDT'), ('earned', 'VBD'), ('him', 'PRP'), ('an', 'DT'), ('Academy', 'NNP'), ('Award', 'NNP'), ('nomination', 'NN'), ('.', '.')]\n",
      "[('He', 'PRP'), ('achieved', 'VBD'), ('international', 'JJ'), ('fame', 'NN'), ('as', 'IN'), ('a', 'DT'), ('star', 'NN'), ('in', 'IN'), ('the', 'DT'), ('epic', 'NN'), ('romance', 'NN'), ('Titanic', 'NNP'), ('(', '('), ('1997', 'CD'), (')', ')'), (',', ','), ('which', 'WDT'), ('became', 'VBD'), ('the', 'DT'), ('highest-grossing', 'NN'), ('film', 'NN'), ('at', 'IN'), ('that', 'DT'), ('point', 'NN'), ('.', '.')]\n",
      "[('After', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('commercially', 'RB'), ('failed', 'VBD'), ('films', 'NNS'), (',', ','), ('DiCaprio', 'NNP'), ('starred', 'VBD'), ('in', 'IN'), ('two', 'CD'), ('successful', 'JJ'), ('features', 'NNS'), ('in', 'IN'), ('2002', 'CD'), (':', ':'), ('the', 'DT'), ('biographical', 'JJ'), ('crime', 'NN'), ('drama', 'NN'), ('Catch', 'NNP'), ('Me', 'NNP'), ('If', 'IN'), ('You', 'PRP'), ('Can', 'NNPS'), ('and', 'CC'), ('the', 'DT'), ('historical', 'JJ'), ('drama', 'NN'), ('Gangs', 'NNP'), ('of', 'IN'), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('which', 'WDT'), ('marked', 'VBD'), ('his', 'PRP$'), ('first', 'JJ'), ('of', 'IN'), ('many', 'JJ'), ('collaborations', 'NNS'), ('with', 'IN'), ('director', 'NN'), ('Martin', 'NNP'), ('Scorsese', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text) # SENTENCE Tokenizer\n",
    "    print(sentences)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence) # WORD Tokenizer\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        print(tagged_words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implementing Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter aware tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''So glad to get to talk to everyone at CES, and thanks to all of you who came by. OnePlus Concept One is just the start of something new, and we’re going to be exploring a lot more with ECMF in the future, so stay tuned with us. #OnePlusConceptOne\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_text = brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(w.lower() for w in news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94 \n",
      "\n",
      "could: 87 \n",
      "\n",
      "may: 93 \n",
      "\n",
      "might: 38 \n",
      "\n",
      "must: 53 \n",
      "\n",
      "will: 389 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in modals:\n",
    "    print(m + ':', fdist[m], end = ' ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
